# Linear regression with Multiple features (Multivariate linear regression)

## 一、Introduction of some notation

+ $x^{(i)}$ = features(input) of $i^{th}$ training example, this is a n dimension vector
+ $x_{j}^{(i)}$ = value of feature j in $i^{th}$ training example

So, the hypothesis of linear regression model become like this:
$$
h_{\theta}(x)=\theta_0+\theta_1x_1+...\theta_nx_n
$$
we can define $x_0=1$,so the equation above changed into:
$$
h_{\theta}(x)=\theta_0x_0+\theta_1x_1+...\theta_nx_n
$$
this can be translated into the form of a row vector multiply a column vector:
$$
h_{\theta}(x)=\Theta^TX\\
\Theta=[\theta_0, \theta_1,...\theta_n]^T,X=[x_0,x_1,...x_n]^T
$$


## 二、Gradient descent for multivariate linear regression

Hypothesis:    $h_{\theta}(x)=\Theta^TX=\theta_0x_0+...\theta_nx_n)$

Parameters:   $\theta_0,\theta_1...\theta_n$

Cost function:
$$
J(\Theta)=J(\theta_0,\theta_1,...\theta_n)=\frac{1}{2m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^2
$$
Gradient descent:

Repeat:
$$
\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\Theta)\\
$$
(simultaneously update for every j = 0, 1, ... n)

after calculate, we got formula below:
$$
\theta_j:=\theta_j-\alpha\frac{1}{m}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)}))x_j^{(i)}
$$
(simultaneously update for every j = 0, 1, ... n)



## 三、Feature scaling Trick for Gradient descent for multivariate linear regression

Feature Scaling means that we should make sure features are on a similar scale, so that gradient descent can run much faster.

For instance, we can make $-100<x_1<100$, and $40 < x_2 < 80$ scale to $-1 < \frac{x_1}{100} < 1$ and $1 < \frac{x_2}{40} < 2$.

### 1. Mean normalization

In some performance of feature scaling, we can use **mean normalization**, that is to say, **replace $x_i$ with $x_i-\mu_i$ to make features have approximately zero mean,  $\mu_i$ is the average value of the $x_i$  in the training set.** 

We can also use **standard deviation of the variable**, for instance,
$$
x_i = \frac{x-\mu}{\sigma}
$$


## 四、Make sure gradient descent is working correctly

To make sure gradient descent will work correctly, we should use smaller $\alpha$.

For sufficiently small $\alpha$, $J(\theta)$ should decrease on every iteration.

But if the learning rate $\alpha$ is too small, gradient  descent can be slow to converge.

So, we can try to find a approximately learning rate.

